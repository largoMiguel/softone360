"""
M√≥dulo de caching con Redis para optimizar llamadas a APIs externas
"""
import redis
import json
import hashlib
from typing import Optional, Any, Callable
from functools import wraps
import logging
from datetime import timedelta

logger = logging.getLogger(__name__)

class CacheManager:
    """Gestor de cach√© con Redis"""
    
    def __init__(self, host: str = "localhost", port: int = 6379, db: int = 0):
        """
        Inicializa la conexi√≥n con Redis
        
        Args:
            host: Host de Redis
            port: Puerto de Redis
            db: Base de datos Redis a usar
        """
        try:
            self.redis_client = redis.Redis(
                host=host,
                port=port,
                db=db,
                decode_responses=True,
                socket_connect_timeout=5
            )
            # Test de conexi√≥n
            self.redis_client.ping()
            logger.info("‚úÖ Conexi√≥n exitosa a Redis")
            self.connected = True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è No se pudo conectar a Redis: {str(e)}. Cache deshabilitado.")
            self.connected = False
    
    def get(self, key: str) -> Optional[Any]:
        """Obtener valor del cach√©"""
        if not self.connected:
            return None
        
        try:
            value = self.redis_client.get(key)
            if value:
                logger.debug(f"‚úÖ Cache hit: {key}")
                return json.loads(value)
            return None
        except Exception as e:
            logger.warning(f"Error al obtener del cach√©: {str(e)}")
            return None
    
    def set(self, key: str, value: Any, ttl_seconds: int = 3600) -> bool:
        """
        Guardar valor en el cach√©
        
        Args:
            key: Clave de cach√©
            value: Valor a guardar
            ttl_seconds: Tiempo de vida en segundos (default 1 hora)
        """
        if not self.connected:
            return False
        
        try:
            self.redis_client.setex(
                key,
                ttl_seconds,
                json.dumps(value)
            )
            logger.debug(f"‚úÖ Cache set: {key} (TTL: {ttl_seconds}s)")
            return True
        except Exception as e:
            logger.warning(f"Error al guardar en cach√©: {str(e)}")
            return False
    
    def delete(self, key: str) -> bool:
        """Eliminar clave del cach√©"""
        if not self.connected:
            return False
        
        try:
            self.redis_client.delete(key)
            logger.debug(f"‚úÖ Cache deleted: {key}")
            return True
        except Exception as e:
            logger.warning(f"Error al eliminar del cach√©: {str(e)}")
            return False
    
    def clear(self) -> bool:
        """Limpiar todo el cach√©"""
        if not self.connected:
            return False
        
        try:
            self.redis_client.flushdb()
            logger.info("‚úÖ Cach√© limpiado")
            return True
        except Exception as e:
            logger.warning(f"Error al limpiar cach√©: {str(e)}")
            return False

# Instancia global de cach√©
cache_manager = CacheManager()

def cache_response(ttl_seconds: int = 3600, key_prefix: str = "api") -> Callable:
    """
    Decorador para cachear respuestas de funciones
    
    Args:
        ttl_seconds: Tiempo de vida del cach√© en segundos
        key_prefix: Prefijo para la clave de cach√©
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs) -> Any:
            # Generar clave de cach√© √∫nica basada en funci√≥n y par√°metros
            cache_key = f"{key_prefix}:{func.__name__}:{hashlib.md5(str((args, kwargs)).encode()).hexdigest()}"
            
            # Intentar obtener del cach√©
            cached_value = cache_manager.get(cache_key)
            if cached_value is not None:
                logger.debug(f"üì¶ Usando valor cacheado para {func.__name__}")
                return cached_value
            
            # Ejecutar funci√≥n y cachear resultado
            result = await func(*args, **kwargs)
            cache_manager.set(cache_key, result, ttl_seconds)
            
            return result
        return wrapper
    return decorator

# Configuraciones de cach√© predefinidas
CACHE_CONFIGS = {
    "datos_gov_proxy": {
        "ttl": 3600,        # 1 hora
        "prefix": "datos_gov"
    },
    "bpin_details": {
        "ttl": 7200,        # 2 horas
        "prefix": "bpin"
    },
    "contratacion_summary": {
        "ttl": 1800,        # 30 minutos (datos m√°s frescos por IA)
        "prefix": "resumen_ia"
    }
}
